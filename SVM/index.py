# 这是一个稍微比较简单的例子


from sklearn import svm

x = [[2, 0], [1, 1], [2, 3]]
y = [0, 0, 1]

# kernel = 'linear' 表示使用的是线性的核函数
clf = svm.SVC(kernel = 'linear')
clf.fit(x, y)

# 打印 模型
print(clf)

# 打印 支持向量，即超平面计算出来后，对于超平面成立（即左右两边）的所有的点，成为支持向量点
print(clf.support_vectors_)
# [
#     [1, 1],
#     [2, 3]
# ]

# 打印 支持向量对应的输入数据的下标
print(clf.support_)
# [1, 2]
# x = [[2, 0], [1, 1], [2, 3]]，所以第一个支持向量[1, 1]对应的下标是1， 第二个支持向量[2, 3]对应的下标是2

# 打印 位于左右两边的支持向量的个数
print(clf.n_support_)
# [1, 1]
# 比如 [[1, 1], [2, 3]]位于超平面的左右两边，而且各一个，所以是[1, 1]

# 输入新的数据进行预测
print(clf.predict([[2, 0]]))
# [0]